{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 100832:   0%|          | 0/1 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_4.png and part_5.png for folder 100832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 100832: 100%|██████████| 1/1 [01:35<00:00, 95.16s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download error: name 'save_image_path' is not defined\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/result/100832/part_4.png and /data_lg/keru/DP_gpt_250502/result/100832/part_5.png for folder 100832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base URL and model configuration for OpenAI API\n",
    "base_url = \"\"\n",
    "api_key = \"\"\n",
    "model = \"sora_image\"  # Use your actual model name here, e.g., \"gpt-4o-image-vip\"\n",
    "client = openai.OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def download_image(image_url, save_path):\n",
    "    try:\n",
    "        # Clean the URL and extract the valid part\n",
    "        image_url = image_url.strip().rstrip(')')\n",
    "        # Use regex to extract the full URL (starting with http/https and including image extensions)\n",
    "        url_match = re.search(r'(https?://[^\\s]+\\.(?:png|jpg|jpeg|gif|bmp|webp))', image_url, re.IGNORECASE)\n",
    "        if not url_match:\n",
    "            print(f\"Invalid URL format: {image_url}\")\n",
    "            return\n",
    "        image_url = url_match.group(1)\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(image_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as img_file:\n",
    "                img_file.write(response.content)\n",
    "            print(f\"Image saved to {save_path}\")  # Corrected here\n",
    "        else:\n",
    "            print(f\"Download failed (Status {response.status_code}): {image_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def generate_and_save_image(image_paths, folder_name, output_json_path, prompt, model, client, output_image_folder, pair_index):\n",
    "    base64_images = [encode_image(image_path) for image_path in image_paths]\n",
    "\n",
    "    # Creating a unique filename based on the image pair index (e.g., result_0_1, result_2_3)\n",
    "    image_filename = f\"result_{pair_index * 2}_{pair_index * 2 + 1}_generated.jpg\"\n",
    "    save_image_path = os.path.join(output_image_folder, folder_name, image_filename)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(save_image_path), exist_ok=True)\n",
    "\n",
    "    configure = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_images[0]}\"}}  # Image 1\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Generating the image based on the provided prompt\n",
    "    #response = client.chat.completions.create(**configure)\n",
    "    response = client.chat.completions.create(\n",
    "    **configure,\n",
    ")\n",
    "    data = response.choices[0].message.content\n",
    "\n",
    "    # Downloading the generated image\n",
    "    download_image(data, save_image_path)\n",
    "\n",
    "    output_log = {\"image_paths\": image_paths, \"response\": data}\n",
    "    with open(output_json_path, 'a') as json_file:\n",
    "        json.dump(output_log, json_file, indent=4)\n",
    "        json_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "def process_images_from_folder(folder_path, output_json_path, prompt_groups, model, client, output_image_folder):\n",
    "    folder_name = os.path.basename(folder_path)  # Extract the folder name (e.g., \"100831\")\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Sort the images based on the numeric part of the filename\n",
    "    image_files.sort(key=lambda x: int(re.search(r'part_(\\d+)', x).group(1)))  # Sort by the number after 'part_'\n",
    "\n",
    "    # Process images in pairs of (0,1), (2,3), (4,5), ...\n",
    "    for i in tqdm(range(0, len(image_files), 2), desc=f\"Processing Images for Folder {folder_name}\", unit=\"pair\"):\n",
    "        # Get the two images (pair) corresponding to a particular subject\n",
    "        image_paths = [os.path.join(folder_path, image_files[i]), os.path.join(folder_path, image_files[i + 1])]\n",
    "        print(f\"Processing pair: {image_files[i]} and {image_files[i + 1]} for folder {folder_name}\")\n",
    "        \n",
    "        # Determine the correct prompt for the pair (0-1 for upper body, 2-3 for lower body, etc.)\n",
    "        pair_index = i // 2\n",
    "        prompt = prompt_groups[pair_index]  # Assuming prompt_groups matches the order 0-1, 2-3, 4-5\n",
    "        generate_and_save_image(image_paths, folder_name, output_json_path, prompt, model, client, output_image_folder, pair_index)\n",
    "        print(f\"Processed pair: {image_paths[0]} and {image_paths[1]} for folder {folder_name}\")\n",
    "\n",
    "\n",
    "# Example Configuration (you need to replace these with actual parameters)\n",
    "folder_path = \"/data_lg/keru/DP_gpt_250502/result/100832\"\n",
    "output_json_path = \"/data_lg/keru/DP_gpt_250502/output_log.json\"\n",
    "output_image_folder = \"/data_lg/keru/DP_gpt_250502/generated_images\"\n",
    "os.makedirs(output_image_folder, exist_ok=True)\n",
    "\n",
    "# Define prompt groups for each image pair (0-1, 2-3, 4-5)\n",
    "prompt_groups = [\n",
    "    \"这是一件上装的前后，请参照为我重新生成上装的前后面,并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2（上装前面宽为768，上装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\",\n",
    "    \"这是一件下装的前后，请参照为我重新生成下装的前后面 并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2（下装前面宽为768，下装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\",\n",
    "    \"这是一件套装的前后，套装可能是裙子，背带裤，请将他看作一件整体的衣服。请参照输入为我重新生成套装的前后面 并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2(套装前面宽为768，套装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\"\n",
    "]\n",
    "\n",
    "# Process images from the folder\n",
    "process_images_from_folder(folder_path, output_json_path, prompt_groups, model, client, output_image_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 100832:   0%|          | 0/1 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_4.png and part_5.png for folder 100832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 100832: 100%|██████████| 1/1 [01:29<00:00, 89.85s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/100832/result_4_5_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/result/100832/part_4.png and /data_lg/keru/DP_gpt_250502/result/100832/part_5.png for folder 100832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base URL and model configuration for OpenAI API\n",
    "base_url = \"\"\n",
    "api_key = \"\"\n",
    "model = \"sora_image\"  # Use your actual model name here, e.g., \"gpt-4o-image-vip\"\n",
    "client = openai.OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def download_image(image_url, save_path):\n",
    "    try:\n",
    "        # Clean the URL and extract the valid part\n",
    "        image_url = image_url.strip().rstrip(')')\n",
    "        # Use regex to extract the full URL (starting with http/https and including image extensions)\n",
    "        url_match = re.search(r'(https?://[^\\s]+\\.(?:png|jpg|jpeg|gif|bmp|webp))', image_url, re.IGNORECASE)\n",
    "        if not url_match:\n",
    "            print(f\"Invalid URL format: {image_url}\")\n",
    "            return\n",
    "        image_url = url_match.group(1)\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(image_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as img_file:\n",
    "                img_file.write(response.content)\n",
    "            print(f\"Image saved to {save_path}\")  # Corrected here\n",
    "        else:\n",
    "            print(f\"Download failed (Status {response.status_code}): {image_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download error: {e}\")\n",
    "\n",
    "\n",
    "def generate_and_save_image(image_paths, folder_name, output_json_path, prompt, model, client, output_image_folder, pair_index, image_files):\n",
    "    base64_images = [encode_image(image_path) for image_path in image_paths]\n",
    "\n",
    "    # Extract numbers from the image files (e.g., part_4.png -> 4, part_5.png -> 5)\n",
    "    numbers = [re.search(r'part_(\\d+)', image_file).group(1) for image_file in image_files]\n",
    "\n",
    "    # Create a unique filename based on the numbers extracted from the input file names (e.g., result_4_5_generated.jpg)\n",
    "    image_filename = f\"result_{numbers[0]}_{numbers[1]}_generated.jpg\"\n",
    "    save_image_path = os.path.join(output_image_folder, folder_name, image_filename)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(save_image_path), exist_ok=True)\n",
    "\n",
    "    configure = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_images[0]}\"}}  # Image 1\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Generate the image using the model (this part remains unchanged)\n",
    "    response = client.chat.completions.create(**configure)\n",
    "    data = response.choices[0].message.content\n",
    "\n",
    "    # Downloading the generated image\n",
    "    download_image(data, save_image_path)\n",
    "\n",
    "    output_log = {\"image_paths\": image_paths, \"response\": data}\n",
    "    with open(output_json_path, 'a') as json_file:\n",
    "        json.dump(output_log, json_file, indent=4)\n",
    "        json_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "def process_images_from_folder(folder_path, output_json_path, prompt_groups, model, client, output_image_folder):\n",
    "    folder_name = os.path.basename(folder_path)  # Extract the folder name (e.g., \"100832\")\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Sort the images based on the numeric part of the filename\n",
    "    image_files.sort(key=lambda x: int(re.search(r'part_(\\d+)', x).group(1)))  # Sort by the number after 'part_'\n",
    "\n",
    "    # Process images in pairs of (0,1), (2,3), (4,5), ...\n",
    "    for i in tqdm(range(0, len(image_files), 2), desc=f\"Processing Images for Folder {folder_name}\", unit=\"pair\"):\n",
    "        # Get the two images (pair) corresponding to a particular subject\n",
    "        image_paths = [os.path.join(folder_path, image_files[i]), os.path.join(folder_path, image_files[i + 1])]\n",
    "        print(f\"Processing pair: {image_files[i]} and {image_files[i + 1]} for folder {folder_name}\")\n",
    "        \n",
    "        # Determine the correct prompt for the pair (0-1 for upper body, 2-3 for lower body, etc.)\n",
    "        pair_index = i // 2\n",
    "        prompt = prompt_groups[pair_index]  # Assuming prompt_groups matches the order 0-1, 2-3, 4-5\n",
    "        generate_and_save_image(image_paths, folder_name, output_json_path, prompt, model, client, output_image_folder, pair_index, image_files[i:i+2])\n",
    "        print(f\"Processed pair: {image_paths[0]} and {image_paths[1]} for folder {folder_name}\")\n",
    "\n",
    "\n",
    "# Example Configuration (you need to replace these with actual parameters)\n",
    "folder_path = \"/data_lg/keru/DP_gpt_250502/result/100832\"\n",
    "output_json_path = \"/data_lg/keru/DP_gpt_250502/output_log.json\"\n",
    "output_image_folder = \"/data_lg/keru/DP_gpt_250502/generated_images\"\n",
    "os.makedirs(output_image_folder, exist_ok=True)\n",
    "\n",
    "# Define prompt groups for each image pair (0-1, 2-3, 4-5)\n",
    "prompt_groups = [\n",
    "    \"这是一件上装的前后，请参照为我重新生成上装的前后面,并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2（上装前面宽为768，上装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\",\n",
    "    \"这是一件下装的前后，请参照为我重新生成下装的前后面 并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2（下装前面宽为768，下装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\",\n",
    "    \"这是一件套装的前后，套装可能是裙子，背带裤，请将他看作一件整体的衣服。请参照输入为我重新生成套装的前后面 并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2(套装前面宽为768，套装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\"\n",
    "]\n",
    "\n",
    "# Process images from the folder\n",
    "process_images_from_folder(folder_path, output_json_path, prompt_groups, model, client, output_image_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 批量处理多个subject id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images in folder 204089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 204089:   0%|          | 0/1 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_4.png and part_5.png for folder 204089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 204089: 100%|██████████| 1/1 [01:18<00:00, 78.15s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/204089/result_4_5_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/204089/part_4.png and /data_lg/keru/DP_gpt_250502/valid_result/204089/part_5.png for folder 204089\n",
      "Processing images in folder 103214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103214:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 103214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103214:  50%|█████     | 1/2 [01:21<01:21, 81.22s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/103214/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/103214/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/103214/part_1.png for folder 103214\n",
      "Processing pair: part_2.png and part_3.png for folder 103214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103214: 100%|██████████| 2/2 [02:50<00:00, 85.45s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/103214/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/103214/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/103214/part_3.png for folder 103214\n",
      "Processing images in folder 103519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103519:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 103519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103519:  50%|█████     | 1/2 [01:11<01:11, 71.34s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/103519/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/103519/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/103519/part_1.png for folder 103519\n",
      "Processing pair: part_2.png and part_3.png for folder 103519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103519: 100%|██████████| 2/2 [02:34<00:00, 77.22s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/103519/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/103519/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/103519/part_3.png for folder 103519\n",
      "Processing images in folder 203518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203518:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 203518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203518:  50%|█████     | 1/2 [01:23<01:23, 83.01s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/203518/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/203518/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/203518/part_1.png for folder 203518\n",
      "Processing pair: part_2.png and part_3.png for folder 203518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203518: 100%|██████████| 2/2 [03:23<00:00, 101.73s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/203518/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/203518/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/203518/part_3.png for folder 203518\n",
      "Processing images in folder 203927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203927:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 203927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203927:  50%|█████     | 1/2 [01:26<01:26, 86.53s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/203927/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/203927/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/203927/part_1.png for folder 203927\n",
      "Processing pair: part_2.png and part_3.png for folder 203927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203927: 100%|██████████| 2/2 [02:39<00:00, 79.75s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/203927/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/203927/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/203927/part_3.png for folder 203927\n",
      "Processing images in folder 103806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103806:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 103806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103806:  50%|█████     | 1/2 [01:22<01:22, 82.70s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/103806/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/103806/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/103806/part_1.png for folder 103806\n",
      "Processing pair: part_2.png and part_3.png for folder 103806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 103806: 100%|██████████| 2/2 [02:41<00:00, 80.61s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/103806/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/103806/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/103806/part_3.png for folder 103806\n",
      "Processing images in folder 201002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 201002:   0%|          | 0/1 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_4.png and part_5.png for folder 201002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 201002: 100%|██████████| 1/1 [01:29<00:00, 89.87s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/201002/result_4_5_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/201002/part_4.png and /data_lg/keru/DP_gpt_250502/valid_result/201002/part_5.png for folder 201002\n",
      "Processing images in folder 201269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 201269:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 201269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 201269:  50%|█████     | 1/2 [01:16<01:16, 76.47s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/201269/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/201269/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/201269/part_1.png for folder 201269\n",
      "Processing pair: part_2.png and part_3.png for folder 201269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 201269: 100%|██████████| 2/2 [02:27<00:00, 73.70s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/201269/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/201269/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/201269/part_3.png for folder 201269\n",
      "Processing images in folder 203668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203668:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 203668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203668:  50%|█████     | 1/2 [01:21<01:21, 81.87s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/203668/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/203668/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/203668/part_1.png for folder 203668\n",
      "Processing pair: part_2.png and part_3.png for folder 203668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 203668: 100%|██████████| 2/2 [02:44<00:00, 82.47s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/203668/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/203668/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/203668/part_3.png for folder 203668\n",
      "Processing images in folder 200206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 200206:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 200206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 200206:  50%|█████     | 1/2 [01:19<01:19, 79.21s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/200206/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/200206/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/200206/part_1.png for folder 200206\n",
      "Processing pair: part_2.png and part_3.png for folder 200206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 200206: 100%|██████████| 2/2 [02:32<00:00, 76.10s/pair]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/200206/result_2_3_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/200206/part_2.png and /data_lg/keru/DP_gpt_250502/valid_result/200206/part_3.png for folder 200206\n",
      "Processing images in folder 202844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 202844:   0%|          | 0/2 [00:00<?, ?pair/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pair: part_0.png and part_1.png for folder 202844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images for Folder 202844:  50%|█████     | 1/2 [01:25<01:25, 85.73s/pair]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /data_lg/keru/DP_gpt_250502/generated_images/202844/result_0_1_generated.jpg\n",
      "Processed pair: /data_lg/keru/DP_gpt_250502/valid_result/202844/part_0.png and /data_lg/keru/DP_gpt_250502/valid_result/202844/part_1.png for folder 202844\n",
      "Processing pair: part_2.png and part_3.png for folder 202844\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base URL and model configuration for OpenAI API\n",
    "base_url = \"\"\n",
    "api_key = \"\"\n",
    "model = \"sora_image\"  # Use your actual model name here, e.g., \"gpt-4o-image-vip\"\n",
    "client = openai.OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def download_image(image_url, save_path):\n",
    "    try:\n",
    "        # Clean the URL and extract the valid part\n",
    "        image_url = image_url.strip().rstrip(')')\n",
    "        # Use regex to extract the full URL (starting with http/https and including image extensions)\n",
    "        url_match = re.search(r'(https?://[^\\s]+\\.(?:png|jpg|jpeg|gif|bmp|webp))', image_url, re.IGNORECASE)\n",
    "        if not url_match:\n",
    "            print(f\"Invalid URL format: {image_url}\")\n",
    "            return\n",
    "        image_url = url_match.group(1)\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(image_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as img_file:\n",
    "                img_file.write(response.content)\n",
    "            print(f\"Image saved to {save_path}\")  # Corrected here\n",
    "        else:\n",
    "            print(f\"Download failed (Status {response.status_code}): {image_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download error: {e}\")\n",
    "\n",
    "\n",
    "def generate_and_save_image(image_paths, folder_name, output_json_path, prompt, model, client, output_image_folder, pair_index, image_files):\n",
    "    base64_images = [encode_image(image_path) for image_path in image_paths]\n",
    "\n",
    "    # Extract numbers from the image files (e.g., part_4.png -> 4, part_5.png -> 5)\n",
    "    numbers = [re.search(r'part_(\\d+)', image_file).group(1) for image_file in image_files]\n",
    "\n",
    "    # Create a unique filename based on the numbers extracted from the input file names (e.g., result_4_5_generated.jpg)\n",
    "    image_filename = f\"result_{numbers[0]}_{numbers[1]}_generated.jpg\"\n",
    "    save_image_path = os.path.join(output_image_folder, folder_name, image_filename)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(save_image_path), exist_ok=True)\n",
    "\n",
    "    configure = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_images[0]}\"}}  # Image 1\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Generate the image using the model (this part remains unchanged)\n",
    "    response = client.chat.completions.create(**configure)\n",
    "    data = response.choices[0].message.content\n",
    "\n",
    "    # Downloading the generated image\n",
    "    download_image(data, save_image_path)\n",
    "\n",
    "    output_log = {\"image_paths\": image_paths, \"response\": data}\n",
    "    with open(output_json_path, 'a') as json_file:\n",
    "        json.dump(output_log, json_file, indent=4)\n",
    "        json_file.write(\"\\n\")\n",
    "\n",
    "\n",
    "def process_images_from_folder(folder_path, output_json_path, prompt_groups, model, client, output_image_folder):\n",
    "    # Iterate over all subject ID folders in the main folder\n",
    "    subject_folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "\n",
    "    for folder_name in subject_folders:\n",
    "        subject_folder_path = os.path.join(folder_path, folder_name)\n",
    "        print(f\"Processing images in folder {folder_name}\")\n",
    "\n",
    "        image_files = [f for f in os.listdir(subject_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        # Sort the images based on the numeric part of the filename\n",
    "        image_files.sort(key=lambda x: int(re.search(r'part_(\\d+)', x).group(1)))  # Sort by the number after 'part_'\n",
    "\n",
    "        # Process images in pairs of (0,1), (2,3), (4,5), ...\n",
    "        for i in tqdm(range(0, len(image_files), 2), desc=f\"Processing Images for Folder {folder_name}\", unit=\"pair\"):\n",
    "            # Get the two images (pair) corresponding to a particular subject\n",
    "            image_paths = [os.path.join(subject_folder_path, image_files[i]), os.path.join(subject_folder_path, image_files[i + 1])]\n",
    "            print(f\"Processing pair: {image_files[i]} and {image_files[i + 1]} for folder {folder_name}\")\n",
    "            \n",
    "            # Determine the correct prompt for the pair (0-1 for upper body, 2-3 for lower body, etc.)\n",
    "            pair_index = i // 2\n",
    "            prompt = prompt_groups[pair_index]  # Assuming prompt_groups matches the order 0-1, 2-3, 4-5\n",
    "            generate_and_save_image(image_paths, folder_name, output_json_path, prompt, model, client, output_image_folder, pair_index, image_files[i:i+2])\n",
    "            print(f\"Processed pair: {image_paths[0]} and {image_paths[1]} for folder {folder_name}\")\n",
    "\n",
    "\n",
    "# Example Configuration (you need to replace these with actual parameters)\n",
    "folder_path = \"/data_lg/keru/DP_gpt_250502/valid_result\"\n",
    "output_json_path = \"/data_lg/keru/DP_gpt_250502/output_log.json\"\n",
    "output_image_folder = \"/data_lg/keru/DP_gpt_250502/generated_images\"\n",
    "os.makedirs(output_image_folder, exist_ok=True)\n",
    "\n",
    "# Define prompt groups for each image pair (0-1, 2-3, 4-5)\n",
    "prompt_groups = [\n",
    "    \"这是一件上装的前后，请参照为我重新生成上装的前后面,并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2（上装前面宽为768，上装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\",\n",
    "    \"这是一件下装的前后，请参照为我重新生成下装的前后面 并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2（下装前面宽为768，下装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\",\n",
    "    \"这是一件套装的前后，套装可能是裙子，背带裤，请将他看作一件整体的衣服。请参照输入为我重新生成套装的前后面 并将结果拼接呈现 ,高清,还原花纹、颜色、样式,背景为白色,细节清晰,图片规格,高1024,宽768*2(套装前面宽为768，套装后面为768），生成结果尽量保持居中，衣服长宽比需合理。\"\n",
    "]\n",
    "\n",
    "# Process images from the folder\n",
    "process_images_from_folder(folder_path, output_json_path, prompt_groups, model, client, output_image_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFLD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
